import numpy as np
import pandas as pd


data = pd.read_csv("../datasets/cbecs2018_final_public.csv")


data.shape


data.head()


data.columns


data.describe()


columns = ["DATACNTR", "TRNGRM", "STDNRM", "LGOFFDEV", "SMOFFDEV", "SERVER", "LAPTOP", "RFGSTO", "ELCOOL","GOVOWN", "PVC", \
           "PCTERMN", "LAPTPN", "TABLETN","SERVERN", "LGOFFDEVN", "SMOFFDEVN", "WBOARDSN", "COOLP", "DCNTRSFC", "ELEXP"]


df = data[columns]


df.head()


df.describe()


missing_values = df.isnull().sum()
print(missing_values)



df = df.dropna(subset=['ELEXP'])
df.shape


cat_cols = ["DATACNTR", "TRNGRM", "STDNRM", "LGOFFDEV", "SMOFFDEV", "SERVER", "LAPTOP", "RFGSTO", "ELCOOL","GOVOWN", "PVC", "DCNTRSFC" ]
cont_cols = ["PCTERMN", "LAPTPN", "TABLETN","SERVERN", "LGOFFDEVN", "SMOFFDEVN", "WBOARDSN", "COOLP", "ELEXP"]


unique_counts = df[cat_cols+cont_cols].nunique()
print(unique_counts)








import matplotlib.pyplot as plt


num_cols = len(cont_cols)

# Create subplots
rows = (num_cols + 1) // 2  # Calculate the number of rows needed
fig, axes = plt.subplots(rows, 2, figsize=(12, rows * 4))  # Adjust figure size
axes = axes.flatten()  # Flatten axes for easy iteration

# Plot histograms
for i, col in enumerate(cont_cols):
    axes[i].hist(df[col].dropna(), bins=40, alpha=0.7, color='blue')  # Exclude NA values
    axes[i].set_title(f'Histogram of {col}')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Frequency')

# Hide unused subplots
for j in range(i + 1, len(axes)):
    axes[j].axis('off')

# Adjust layout
plt.tight_layout()
plt.show()



import seaborn as sns
import matplotlib.pyplot as plt

# Create a pair plot
sns.pairplot(df[cont_cols], diag_kind='kde', corner=True)  # 'diag_kind' for diagonal plots; 'corner=True' for a lower triangle plot
plt.show()



%matplotlib inline

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Compute the correlation matrix for numerical columns
correlation_matrix = df[cont_cols].corr()

# Create a mask for the upper triangle
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))

# Plot the heatmap
plt.figure(figsize=(10, 8))  # Adjust the size as needed
sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt=".2f", cmap="coolwarm", cbar=True, annot_kws={"size": 10})
plt.title("Correlation Matrix", fontsize=16)
plt.tight_layout()
plt.show()






import matplotlib.pyplot as plt



# Determine the number of rows and columns for subplots
n_cols = 2  # Number of pie charts per row
n_rows = (len(cat_cols) + n_cols - 1) // n_cols  # Calculate the number of rows

# Create a subplot grid
fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))
axes = axes.flatten()  # Flatten the axes array for easy iteration

# Loop through each categorical column and plot the pie chart
for i, col in enumerate(cat_cols):
    value_counts = df[col].value_counts(normalize=True) * 100  # Percentage of unique values
    labels = value_counts.index  # Categories as labels
    sizes = value_counts.values  # Percentages as sizes

    axes[i].pie(sizes, labels=labels, autopct="%.1f%%", startangle=90)
    axes[i].set_title(f"Distribution of {col}")

# Remove any extra subplots (if cat_cols < total grid slots)
for j in range(len(cat_cols), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()






import seaborn as sns
import matplotlib.pyplot as plt

# Assume `cat_cols` contains the list of categorical columns
# Assume `num_col` is the numerical column for box plots
num_col = 'ELEXP'       # Replace with your actual numerical column

# Iterate through each categorical column
for cat_col in cat_cols:
    plt.figure(figsize=(10, 6))  # Set figure size
    sns.boxplot(x=cat_col, y=num_col, data=df)
    plt.title(f"Box Plot of {num_col} by {cat_col}")
    plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility
    plt.tight_layout()
    plt.show()



from scipy.stats import f_oneway

target_col = "ELEXP"
for cat_col in cat_cols:
    df1 = df.dropna(subset=[cat_col, target_col])
    # Group numerical target by each category in the categorical column
    groups = [df1[target_col][df1[cat_col] == category] for category in df1[cat_col].unique()]
    
    # Perform ANOVA
    f_stat, p_value = f_oneway(*groups)
    
    # Display Results
    print(f"ANOVA results for {cat_col}:")
    print(f"F-statistic: {f_stat:.4f}, P-value: {p_value:.4f}")
    print("-" * 40)



from scipy.stats import kruskal


for cat_col in cat_cols:
    # Group the target variable by each category in the categorical column
    df1 = df.dropna(subset=[cat_col, target_col])
    groups = [df1[target_col][df1[cat_col] == category] for category in df1[cat_col].unique()]
    
    # Perform Kruskal-Wallis Test
    h_stat, p_value = kruskal(*groups)
    
    # Display Results
    print(f"Kruskal-Wallis Test results for {cat_col}:")
    print(f"H-statistic: {h_stat:.4f}, P-value: {p_value:.4f}")
    print("-" * 40)







# cat_cols = ["DATACNTR", "TRNGRM", "STDNRM", "LGOFFDEV", "SMOFFDEV", "SERVER", "LAPTOP", "RFGSTO", "ELCOOL","GOVOWN"]
# cont_cols = ["PCTERMN", "LAPTPN", "TABLETN","SERVERN", "LGOFFDEVN", "SMOFFDEVN", "WBOARDSN", "COOLP", "ELEXP"]
# Replace NaN with median for all numerical columns
df_imputed_0 = df[cont_cols+cat_cols]
df_imputed_0[cont_cols] = df_imputed_0[cont_cols].apply(lambda col: col.fillna(col.median()))

# Replace NaN with the mode (most frequent category) for categorical columns
df_imputed_0[cat_cols] = df_imputed_0[cat_cols].apply(lambda col: col.fillna(col.mode()[0]))


from sklearn.impute import KNNImputer
import pandas as pd

# Assuming df is the DataFrame and cont_cols, cat_cols are already defined

# Create a copy of the dataframe to avoid modifying the original one
df_imputed = df.copy()

# Separate continuous and categorical columns
X_continuous = df_imputed[cont_cols]
X_categorical = df_imputed[cat_cols]

# KNN Imputation for Continuous Columns
knn_imputer = KNNImputer(n_neighbors=5)
df_imputed[cont_cols] = knn_imputer.fit_transform(X_continuous)

# KNN Imputation for Categorical Columns (using the mode for categorical features)
# First, convert categorical columns to numeric for KNN imputation (using label encoding)
X_categorical_encoded = X_categorical.apply(lambda col: col.astype('category').cat.codes)

# Perform KNN imputation for categorical data
df_imputed[cat_cols] = knn_imputer.fit_transform(X_categorical_encoded)

# Convert back to original categorical values (decode the encoded labels)
df_imputed[cat_cols] = df_imputed[cat_cols].apply(lambda col: col.astype('category').cat.codes)
for col in cat_cols:
    df_imputed[col] = df_imputed[col].astype('category')

# Output the imputed dataframe
print(df_imputed.head())






import pandas as pd

# One-hot encode categorical columns
df_data_prep = pd.get_dummies(df_imputed, columns=cat_cols, drop_first=True)  # drop_first=True avoids dummy variable trap

# Convert all columns to integers
df_data_prep = df_data_prep.astype(int)

print("DataFrame after converting all columns to integers:")
print(df_data_prep.info())



from sklearn.preprocessing import MinMaxScaler

# Select the columns you want to normalize (typically numerical columns)
columns_to_normalize = cont_cols  # Assuming `cont_cols` contains numerical column names

# Initialize MinMaxScaler with the desired feature range
scaler = MinMaxScaler(feature_range=(-1, 1))

# Normalize the selected columns
df_data_prep[columns_to_normalize] = scaler.fit_transform(df_data_prep[columns_to_normalize])

print("One-hot encoded DataFrame & Normalized DataFrame:") 
print(df_data_prep.head())
print(df_data_prep.columns)


import statsmodels.api as sm
import numpy as np
import pandas as pd



# Prepare the features (X) and target (y)
X = df_data_prep.drop(columns=[target_col])
y = df[target_col]

# Add an intercept (constant) to the model
X_encoded = sm.add_constant(X)

# Fit the model using statsmodels
model = sm.OLS(y, X_encoded)
results = model.fit()

# Print the summary of the model (which includes p-values)
print(results.summary())

# Extract the p-values for each feature and interaction term
p_values = results.pvalues
print(p_values)



X.shape


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns


X = df_data_prep.drop(columns=[target_col])  # Features (independent variables)
y = df_data_prep[target_col]  # Target (dependent variable)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("Sahpe of X_train", X_train.shape)
print("Shape of X_test", X_test.shape)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.4f}")
print(f"RÂ² Score: {r2:.4f}")

sns.residplot(x=y_test, y=y_pred, lowess=True, color="g", line_kws={'color': 'red'})
plt.title("Residual Plot")
plt.show()

plt.scatter(y_test, y_pred)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--r', lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted")
plt.show()



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.linear_model import Ridge, Lasso, ElasticNet, SGDRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# Define features and target
X = df_data_prep.drop(columns=[target_col])  # Features (independent variables)
y = df_data_prep[target_col]  # Target (dependent variable)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)

# Define models and their hyperparameter grids
models = {
    "Ridge": Ridge(),
    "Lasso": Lasso(),
    "ElasticNet": ElasticNet(),
    "SGD": SGDRegressor(max_iter=1000, tol=1e-3)  # Added SGD Regressor
}

param_grids = {
    "Ridge": {"alpha": [0.01, 0.1, 1, 10, 100]},
    "Lasso": {"alpha": [0.01, 0.1, 1, 10, 100]},
    "ElasticNet": {
        "alpha": [0.01, 0.1, 1, 10, 100],
        "l1_ratio": [0.1, 0.5, 0.7, 1.0]
    },
    "SGD": {
        "alpha": [0.01, 0.1, 1, 10, 100],  # Regularization strength
        "penalty": ['l2', 'l1', 'elasticnet'],  # Regularization type
        "learning_rate": ['constant', 'optimal', 'invscaling']  # Learning rate
    }
}

best_models = {}
best_scores = {}

# Perform grid search for each model
for model_name, model in models.items():
    print(f"Tuning {model_name}...")
    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=5, scoring='r2', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_models[model_name] = grid_search.best_estimator_
    best_scores[model_name] = grid_search.best_score_
    print(f"Best {model_name} Parameters: {grid_search.best_params_}")
    print(f"Best {model_name} RÂ² (CV): {grid_search.best_score_:.4f}")

# Evaluate the best model on the test set
best_model_name = max(best_scores, key=best_scores.get)
best_model = best_models[best_model_name]

print(f"\nBest Model: {best_model_name}")
best_model.fit(X_train, y_train)
y_pred = best_model.predict(X_test)

# Calculate performance metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (Test): {mse:.4f}")
print(f"RÂ² Score (Test): {r2:.4f}")

# Perform Cross-validation for the best model
cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='r2')
print(f"Cross-Validation RÂ² Scores: {cv_scores}")
print(f"Mean Cross-Validation RÂ²: {cv_scores.mean():.4f}")

# Residual plot
sns.residplot(x=y_test, y=y_pred, lowess=True, color="g", line_kws={'color': 'red'})
plt.title("Residual Plot")
plt.xlabel("Actual")
plt.ylabel("Residuals")
plt.show()

# Actual vs Predicted plot
plt.scatter(y_test, y_pred)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--r', lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted")
plt.show()



# Assume `cont_cols` is a list of continuous columns in your dataset
cont_cols_1 = cont_cols
cont_cols_1.remove("ELEXP")

# Create a new dataframe `df_poly` with squared terms for continuous columns
df_poly = df_data_prep.copy()
for col in cont_cols:
    if col != "ELEXP":
        df_poly[f"{col}^2"] = df_poly[col] ** 2

# Visualize relationships with a pair plot
sns.pairplot(df_poly, x_vars=cont_cols + [f"{col}^2" for col in cont_cols], y_vars=target_col, kind='scatter', diag_kind='kde', plot_kws={'alpha': 0.7})
plt.suptitle("Pair Plot of Features (Including Squared Terms) vs Target", y=1.02)
plt.show()

# Define features and target from `df_poly`
X_poly = df_poly.drop(columns=[target_col])
y_poly = df_poly[target_col]

# Split the data into training and testing sets
X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(X_poly, y_poly, test_size=0.2, random_state=42)
print("Shape of X_poly_train:", X_poly_train.shape)
print("Shape of X_poly_test:", X_poly_test.shape)

# Train a Linear Regression model on the new dataset with squared terms
model_poly = LinearRegression()
model_poly.fit(X_poly_train, y_poly_train)

# Make predictions
y_poly_pred = model_poly.predict(X_poly_test)

# Evaluate the model
mse_poly = mean_squared_error(y_poly_test, y_poly_pred)
r2_poly = r2_score(y_poly_test, y_poly_pred)

print(f"Linear Regression with Squared Terms Performance:")
print(f"Mean Squared Error: {mse_poly:.4f}")
print(f"RÂ² Score: {r2_poly:.4f}")

# Visualizations for the new model
sns.residplot(x=y_poly_test, y=y_poly_pred, lowess=True, color="b", line_kws={'color': 'red'})
plt.title("Residual Plot (Squared Terms)")
plt.show()

plt.scatter(y_poly_test, y_poly_pred)
plt.plot([min(y_poly_test), max(y_poly_test)], [min(y_poly_test), max(y_poly_test)], '--r', lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted (Squared Terms)")
plt.show()



df_data_prep


import pandas as pd

# Assuming df_data_prep is your DataFrame and 'ELEXP' is the column of interest
def remove_outliers_iqr(df, column):
    """
    Removes outliers from the specified column based on the IQR method.
    
    Args:
    df (pd.DataFrame): The input DataFrame.
    column (str): The column from which outliers need to be removed.

    Returns:
    pd.DataFrame: The DataFrame with outliers removed from the specified column.
    """
    Q1 = df[column].quantile(0.25)  # First quartile
    Q3 = df[column].quantile(0.75)  # Third quartile
    IQR = Q3 - Q1  # Interquartile range

    # Define the lower and upper bounds for outliers
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Filter the DataFrame to exclude outliers
    df_no_outliers = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

    return df_no_outliers

# Apply the function to remove outliers from the 'ELEXP' column
df_data_no_outliers = remove_outliers_iqr(df_data_prep, 'ELEXP')

# Display the shape of the original and cleaned DataFrame
print(f"Original shape: {df_data_prep.shape}")
print(f"Shape after removing outliers: {df_data_no_outliers.shape}")



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# Prepare the data (assuming target_col is defined and df_data_no_outliers is the cleaned DataFrame)
X = df_data_no_outliers.drop(columns=[target_col])  # Features (independent variables)
y = df_data_no_outliers[target_col]  # Target (dependent variable)

# Split the data into training and test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)

print("Shape of X_train", X_train.shape)
print("Shape of X_test", X_test.shape)

# Train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate evaluation metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.4f}")
print(f"RÂ² Score: {r2:.4f}")

# Plot Residuals
sns.residplot(x=y_test, y=y_pred, lowess=True, color="g", line_kws={'color': 'red'})
plt.title("Residual Plot")
plt.show()

# Plot Actual vs Predicted values
plt.scatter(y_test, y_pred)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--r', lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted")
plt.show()




